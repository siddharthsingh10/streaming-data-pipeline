#!/usr/bin/env python3
"""
MVP Demo: Producer â†’ Kafka â†’ Consumer â†’ Sink

This script demonstrates the minimal viable streaming pipeline:
1. Producer generates events and sends to Kafka
2. Consumer reads from Kafka and processes events
3. Sink writes processed events to Parquet files

Simple, visual demonstration of the core pipeline flow.
"""

import time
import logging
import json
from datetime import datetime
from src.producer import EventProducer
from src.consumer import EventConsumer
from src.transform import EventTransformer
from src.sink_writer import ParquetSinkWriter
from src.config import TOPICS, BATCH_SIZE, BATCH_TIMEOUT_SECONDS

# Setup logging for demo
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def demo_mvp_pipeline():
    """Demo the MVP pipeline flow: Producer â†’ Kafka â†’ Consumer â†’ Sink"""
    
    print("ğŸš€ MVP Demo: Producer â†’ Kafka â†’ Consumer â†’ Sink")
    print("=" * 60)
    
    # Step 1: Initialize Components
    print("\nğŸ“¦ Step 1: Initializing Pipeline Components")
    print("-" * 40)
    
    producer = EventProducer()
    consumer = EventConsumer()
    transformer = EventTransformer()
    sink_writer = ParquetSinkWriter()
    
    print("âœ… Producer initialized")
    print("âœ… Consumer initialized") 
    print("âœ… Transformer initialized")
    print("âœ… Sink writer initialized")
    
    # Step 2: Generate and Send Events
    print("\nğŸ“¤ Step 2: Producer â†’ Kafka")
    print("-" * 40)
    
    events_to_send = 5
    print(f"ğŸ“ Generating {events_to_send} events...")
    
    for i in range(events_to_send):
        event = producer.generate_event()
        producer.send_event(event)
        print(f"  ğŸ“¨ Sent event {i+1}: {event['event_type']} from user {event['user_id']}")
        time.sleep(0.5)  # Visual delay
    
    print("âœ… All events sent to Kafka")
    
    # Step 3: Consume and Process Events
    print("\nğŸ“¥ Step 3: Kafka â†’ Consumer")
    print("-" * 40)
    
    print("ğŸ”„ Consuming events from Kafka...")
    messages = consumer.consume_batch(timeout_seconds=5)
    
    if messages:
        print(f"âœ… Consumed {len(messages)} events from Kafka")
        for i, msg in enumerate(messages):
            event = json.loads(msg.value())
            print(f"  ğŸ“¥ Received event {i+1}: {event['event_type']} from user {event['user_id']}")
    else:
        print("âŒ No events consumed from Kafka")
        return
    
    # Step 4: Transform Events
    print("\nğŸ”„ Step 4: Consumer â†’ Transformer")
    print("-" * 40)
    
    print("ğŸ”„ Transforming events...")
    transformed_events = []
    
    for i, msg in enumerate(messages):
        event = json.loads(msg.value())
        try:
            transformed = transformer.transform_user_event(event)
            transformed_events.append(transformed)
            print(f"  ğŸ”„ Transformed event {i+1}: {event['event_type']} â†’ {transformed['normalized_event_type']}")
        except Exception as e:
            print(f"  âŒ Failed to transform event {i+1}: {e}")
    
    print(f"âœ… Transformed {len(transformed_events)} events")
    
    # Step 5: Write to Sink
    print("\nğŸ’¾ Step 5: Transformer â†’ Sink")
    print("-" * 40)
    
    if transformed_events:
        print("ğŸ”„ Writing events to Parquet sink...")
        
        for i, event in enumerate(transformed_events):
            sink_writer.write_event(event)
            print(f"  ğŸ’¾ Wrote event {i+1}: {event['event_type']} â†’ {event['normalized_event_type']}")
        
        # Flush final batch
        sink_writer.flush()
        stats = sink_writer.get_stats()
        print(f"âœ… Wrote {stats['events_written']} events to Parquet files")
        print(f"ğŸ“ Output location: {sink_writer.output_dir}")
    else:
        print("âŒ No events to write to sink")
    
    # Step 6: Summary
    print("\nğŸ“Š MVP Pipeline Summary")
    print("=" * 60)
    print(f"ğŸ“¤ Events Produced: {events_to_send}")
    print(f"ğŸ“¥ Events Consumed: {len(messages)}")
    print(f"ğŸ”„ Events Transformed: {len(transformed_events)}")
    print(f"ğŸ’¾ Events Written: {len(transformed_events)}")
    print(f"ğŸ“ˆ Success Rate: {(len(transformed_events)/events_to_send)*100:.1f}%")
    
    # Cleanup
    print("\nğŸ§¹ Cleaning up...")
    producer.close()
    consumer.close()
    sink_writer.close()
    print("âœ… Pipeline components closed")
    
    print("\nğŸ‰ MVP Demo Complete!")
    print("=" * 60)
    print("This demonstrates the core flow:")
    print("Producer â†’ Kafka â†’ Consumer â†’ Transformer â†’ Sink")
    print("\nTo run the full pipeline: python main.py")


def demo_with_error_handling():
    """Demo with error handling to show dead letter queue."""
    
    print("\nğŸ”„ Bonus Demo: Error Handling")
    print("=" * 40)
    
    # Create an invalid event
    invalid_event = {
        "user_id": "user123",
        "event_type": "invalid_event_type",  # This will fail validation
        "timestamp": datetime.now().isoformat()
    }
    
    print("ğŸ“ Creating invalid event for error handling demo...")
    
    producer = EventProducer()
    consumer = EventConsumer()
    transformer = EventTransformer()
    
    # Send invalid event
    producer.send_event(invalid_event)
    print("ğŸ“¨ Sent invalid event to Kafka")
    
    # Try to consume and process
    messages = consumer.consume_batch(timeout_seconds=3)
    
    if messages:
        event = json.loads(messages[0].value())
        print(f"ğŸ“¥ Consumed event: {event['event_type']}")
        
        try:
            transformed = transformer.transform_user_event(event)
            print("âœ… Event transformed successfully")
        except Exception as e:
            print(f"âŒ Event failed transformation: {e}")
            print("ğŸ’¡ This would be sent to dead letter queue in full pipeline")
    
    # Cleanup
    producer.close()
    consumer.close()


if __name__ == "__main__":
    try:
        # Main MVP demo
        demo_mvp_pipeline()
        
        # Optional error handling demo
        demo_with_error_handling()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Demo stopped by user")
    except Exception as e:
        print(f"\nâŒ Demo error: {e}")
        print("Make sure Kafka is running: docker-compose up -d") 