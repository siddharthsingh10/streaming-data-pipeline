# Streaming Data Pipeline - Design Document

## üéØ Project Overview

This document outlines the design and implementation of a **minimal yet complete streaming data ingestion pipeline** as specified in the assignment requirements.

## üèó Architecture

### High-Level Design
```
Event Generator ‚Üí Kafka ‚Üí Consumer ‚Üí Transformer ‚Üí Parquet Sink
                                    ‚Üì
                                Dead Letter Queue
```

### Infrastructure Components

#### **Confluent Kafka Platform**
- **Purpose**: Provides reliable message streaming with enterprise features
- **Components**:
  - **Zookeeper**: Coordination service for Kafka cluster
  - **Confluent Kafka**: Enhanced Apache Kafka with additional features
  - **Confluent Control Center**: Web-based monitoring and management UI
- **Design Decision**: Chose Confluent over Bitnami for:
  - Better compatibility and stability
  - Built-in monitoring capabilities
  - Enterprise-grade features
  - Web UI for real-time monitoring

#### **Monitoring & Observability**
- **Confluent Control Center**: Web UI at http://localhost:9021
  - Real-time topic monitoring
  - Message browsing and search
  - Cluster health metrics
  - Consumer group monitoring
  - Dead letter queue inspection
- **Design Decision**: Web UI provides:
  - Visual monitoring of data flow
  - Debugging capabilities
  - Production-ready observability

### Component Breakdown

#### 1. **Event Generator (Producer)**
- **Purpose**: Simulates a streaming data source
- **Implementation**: Synthetic event generation using Faker library
- **Output**: JSON events with realistic user interaction data
- **Features**: 10% invalid event generation for dead letter queue testing
- **Design Decision**: Used Kafka for scalability and real-world relevance

#### 2. **Kafka Message Broker**
- **Purpose**: Provides reliable message streaming
- **Topics**: 
  - `events-topic`: Valid events for processing
  - `dead-letter-topic`: Failed events with error details
- **Design Decision**: Chose Kafka over simple file streaming for:
  - Message persistence and replay capability
  - Scalability and fault tolerance
  - Real-world streaming pipeline patterns

#### 3. **Event Consumer**
- **Purpose**: Processes events from Kafka topics
- **Features**:
  - Batch processing for efficiency
  - Schema validation
  - Error handling and dead letter routing
- **Design Decision**: Batch processing reduces I/O overhead

#### 4. **Event Transformer**
- **Purpose**: Applies meaningful transformations to events
- **Transformations**:
  - **Normalization**: Standardize field formats (timestamps, user agents)
  - **Enrichment**: Add derived fields (session duration, event categories)
  - **Filtering**: Remove invalid or low-value events
- **Design Decision**: Focused on business-value transformations rather than simple field mapping

#### 5. **Parquet Sink Writer**
- **Purpose**: Writes processed events to structured storage
- **Features**:
  - Columnar storage for efficient querying
  - Partitioning by date for data organization
  - Batch writing for performance
- **Design Decision**: Parquet over CSV for:
  - Better compression and query performance
  - Schema preservation
  - Industry standard for data lakes

#### 6. **Dead Letter Queue Handler**
- **Purpose**: Manages failed events and provides error analysis
- **Features**:
  - Error categorization and analysis
  - Detailed error information storage
  - Error pattern detection
- **Design Decision**: Essential for production reliability and debugging

## üîß Design Decisions & Rationale

### 1. **Technology Stack**

**Chosen**: Python with Confluent Kafka, PyArrow, Faker
**Rationale**:
- **Python**: Widely used in data engineering, rich ecosystem
- **Confluent Kafka**: Enterprise-grade Kafka with monitoring capabilities
- **PyArrow**: Efficient Parquet handling, memory-efficient processing
- **Faker**: Generates realistic test data

**Alternatives Considered**:
- Bitnami Kafka (rejected: compatibility issues with newer versions)
- Simple file-based streaming (rejected: lacks real-world relevance)
- CSV output (rejected: Parquet offers better performance and features)

### 2. **Infrastructure Architecture**

**Chosen**: Docker Compose with Confluent Platform
**Rationale**:
- **Confluent Control Center**: Provides web-based monitoring
- **Enterprise Features**: Better stability and compatibility
- **Easy Setup**: Single docker-compose command starts everything
- **Production Ready**: Mirrors enterprise streaming setups

### 3. **Data Flow Architecture**

**Chosen**: Producer ‚Üí Kafka ‚Üí Consumer ‚Üí Transform ‚Üí Sink
**Rationale**:
- **Decoupled components**: Easy to scale and maintain
- **Fault tolerance**: Kafka provides message persistence
- **Real-world pattern**: Mirrors production streaming pipelines

### 4. **Event Schema Design**

**Chosen**: Comprehensive user interaction events
**Rationale**:
- **Realistic data**: Simulates actual business scenarios
- **Rich transformations**: Enables meaningful data processing
- **Validation complexity**: Tests schema validation capabilities

### 5. **Error Handling Strategy**

**Chosen**: Dead letter queue with detailed error analysis
**Rationale**:
- **Data preservation**: No data loss during processing
- **Debugging capability**: Error analysis helps identify issues
- **Web UI monitoring**: Control Center provides visual error inspection

### 6. **Storage Format**

**Chosen**: Parquet with partitioning
**Rationale**:
- **Query performance**: Columnar format enables efficient analytics
- **Compression**: Reduces storage costs
- **Schema evolution**: Supports schema changes over time

### 7. **Monitoring Strategy**

**Chosen**: Confluent Control Center + Application Logging
**Rationale**:
- **Real-time visibility**: Web UI shows live data flow
- **Message inspection**: Browse and search messages
- **Cluster health**: Monitor Kafka cluster status
- **Error tracking**: Visual dead letter queue monitoring

## üìä Data Flow Example

### Sample Event Journey

**1. Event Generation**
```json
{
  "event_id": "evt_123",
  "user_id": "user_456",
  "timestamp": "2024-01-15T10:30:00Z",
  "event_type": "page_view",
  "page_url": "/products/laptop",
  "user_agent": "Mozilla/5.0...",
  "session_id": "sess_789"
}
```

**2. Transformation**
```json
{
  "event_id": "evt_123",
  "user_id": "user_456",
  "timestamp": "2024-01-15T10:30:00Z",
  "event_type": "page_view",
  "page_url": "/products/laptop",
  "user_agent": "Mozilla/5.0...",
  "session_id": "sess_789",
  "normalized_timestamp": "2024-01-15T10:30:00Z",
  "event_category": "engagement",
  "device_type": "desktop",
  "browser": "chrome"
}
```

**3. Storage**
- Written to: `data/output/2024/01/15/events.parquet`
- Partitioned by date for efficient querying

**4. Dead Letter Example**
```json
{
  "original_event": {...},
  "error_type": "ValidationError",
  "error_message": "'invalid_event_type' is not one of ['page_view', 'click', 'purchase', 'signup', 'login', 'logout']",
  "failed_at": "2024-01-15T10:30:00Z",
  "processing_stage": "producer_validation"
}
```

## üöÄ Implementation Phases

### Phase 1: Core Infrastructure
- ‚úÖ Confluent Kafka setup and configuration
- ‚úÖ Confluent Control Center integration
- ‚úÖ Basic producer and consumer

### Phase 2: Data Processing
- ‚úÖ Event transformation logic
- ‚úÖ Schema validation
- ‚úÖ Error handling with dead letter queue

### Phase 3: Storage and Reliability
- ‚úÖ Parquet sink writer
- ‚úÖ Dead letter queue with detailed error info
- ‚úÖ Batch processing

### Phase 4: Monitoring and Observability
- ‚úÖ Web UI monitoring (Control Center)
- ‚úÖ Real-time message inspection
- ‚úÖ Cluster health monitoring

### Phase 5: Production Features
- ‚úÖ Health monitoring
- ‚úÖ Metrics collection
- ‚úÖ Graceful shutdown
- ‚úÖ Manual message generation for testing

## üß™ Testing Strategy

### Test Coverage
- **Unit Tests**: Individual component testing
- **Integration Tests**: End-to-end pipeline testing
- **Error Scenarios**: Dead letter queue testing
- **Performance Tests**: Batch processing validation
- **UI Testing**: Control Center message inspection

### Test Data
- **Valid Events**: Normal processing flow
- **Invalid Events**: Schema validation testing (10% generation)
- **Edge Cases**: Boundary condition testing

## üìà Performance Considerations

### Optimizations Implemented
1. **Batch Processing**: Reduces Kafka overhead
2. **Parquet Compression**: Minimizes storage footprint
3. **Efficient Serialization**: PyArrow for fast data handling
4. **Connection Pooling**: Reuses Kafka connections
5. **Web UI Monitoring**: Real-time observability without performance impact

## üîç Monitoring and Debugging

### Confluent Control Center Features
- **Topic Monitoring**: Real-time message counts and throughput
- **Message Browser**: Search and inspect individual messages
- **Consumer Groups**: Monitor consumer lag and health
- **Cluster Health**: Overall system status and metrics
- **Dead Letter Inspection**: Visual error analysis

### Application Logging
- **Structured Logging**: JSON format for easy parsing
- **Error Tracking**: Detailed error information
- **Performance Metrics**: Processing time and throughput
- **Health Checks**: Component status monitoring 